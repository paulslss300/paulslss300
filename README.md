## Hi there ðŸ‘‹

<!--
**paulslss300/paulslss300** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->

I'm Yuzhi (Paul) Tang, an MScAC student at the University of Toronto. I am deeply passionate about identifying and mitigating risks in large-scale models. Currently, I'm working at the Machine Learning Group at the University of Toronto with Yangjun Ruan and Honghua Dong, where I developed an automatic pipeline to identify and decompose risks in LLM agent trajectories through prompt-tuning, and extended [ToolEmu](https://toolemu.com/) for large-scale evaluation on state-of-the-art LLM agents. My focus is on enhancing the safety and reliability of AI systems by addressing challenges in large-scale model deployment. 

I also received the Undergraduate Student Research Award from NSERC for research in developing a reliability testing framework for computer vision models with Prof. Marsha Chechik. Previously, I applied ML to various healthcare settings, such as adapting [a self-supervised pretraining recipe](https://github.com/paulslss300/SSLMI) for ultrasound image segmentation at the MiDATA lab with Prof. Pascal Tyrrell and developing [an end-to-end ML pipeline for sleep staging](https://academic.oup.com/sleep/article/47/Supplement_1/A481/7655182) at the Sunnybrook Research Institute.

ðŸ”­ **Current Focus:** Risk identification and mitigation in large-scale LLMs.

ðŸŒ± **Learning:** Advanced techniques for improving LLM safety and reliability.

ðŸ‘¯ **Looking to Collaborate:** On projects tackling the complexities and risks of large-scale AI models.

ðŸ“« **Reach Me:** [yuzhi.tang@mail.utoronto.ca](mailto:yuzhi.tang@mail.utoronto.ca)

âš¡ **Fun Fact:** I won 1st place at the IJCAI 2023 Intrinsic Error Evaluation Competition!
